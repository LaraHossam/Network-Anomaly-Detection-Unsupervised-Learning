{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152c8828",
   "metadata": {},
   "source": [
    "# Network Anomaly Detection using Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9dcf3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import random\n",
    "random.seed(42)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813b800",
   "metadata": {},
   "source": [
    "# 1. Importing Data and Understanding Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b4ac7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.data_preprocessing import preprocess_data_10, preprocess_data, category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "36eab8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_k_means, labels_kmeans = preprocess_data_10()\n",
    "data_spectral, labels_spectral = preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98946dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter, OrderedDict\n",
    "# d = Counter(labels_spectral)\n",
    "# OrderedDict(sorted(d.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0051450",
   "metadata": {},
   "source": [
    "# 2.  Clustering Using K-Means and Normalized Cut (Your implementation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b39528",
   "metadata": {},
   "source": [
    "### K-Means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "06553527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It takes two attrs k number of centroids and the whole data set number of samples x features\n",
    "\n",
    "def kMeans_implemented(k,data):\n",
    "    centroids=[]\n",
    "    num_points=data.shape[0]\n",
    "    num_features=data.shape[1]\n",
    "    \n",
    "    #Appending random points to be our centroids according to the number of ks\n",
    "    for i in range(k):\n",
    "        centroids.append(data[random.randint(0, num_points)])\n",
    "    clusters={}\n",
    "    t=0\n",
    "    while(True):\n",
    "        labels=[]\n",
    "        #Initialize empty clusters\n",
    "        for i in range (k):\n",
    "            clusters[i]=[]\n",
    "            \n",
    "        #Classify the points according to the closest centroid\n",
    "        for i in range(num_points):\n",
    "            distances=[]\n",
    "            for j in range(k):\n",
    "                distances.append(np.linalg.norm(data[i]-centroids[j]))\n",
    "            clusters[distances.index(min(distances))].append(data[i])\n",
    "            labels.append(distances.index(min(distances)))\n",
    "        new_centroids=np.zeros((k,num_features))\n",
    "        \n",
    "        #Measuring the new centroids\n",
    "        for i in range(k):\n",
    "            new_centroids[i]=np.mean(clusters[i],axis=0)\n",
    "        if(centroids==new_centroids).all():\n",
    "            break\n",
    "        else:\n",
    "            centroids=new_centroids\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225e45c",
   "metadata": {},
   "source": [
    "### Spectral Clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ac6f2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def spectral_clustering(A,k):\n",
    "        \n",
    "    #--------------computing the degree matrix-------------\n",
    "    d = np.diag(np.sum(A, axis=1))\n",
    "\n",
    "    #--------------------computing L-----------------------\n",
    "    L = d-A\n",
    "\n",
    "    #---------------------computing La---------------------\n",
    "    #computing the inverse of the dgree matrix\n",
    "    inv_degree = np.linalg.inv(d)\n",
    "    La = np.dot(inv_degree, L)\n",
    "\n",
    "    #---computing the eigenValues and eigenVectors of La---\n",
    "    e_val, evec = np.linalg.eig(La)\n",
    "\n",
    "    #----------sorting the eigenValues ascending----------- \n",
    "    idx = np.argsort(eval)\n",
    "    e_val = e_val[idx]\n",
    "\n",
    "    #---sorting the eigenVectors according to their corresponding eigenValues---\n",
    "    evec = evec[:, idx]\n",
    "\n",
    "    #--slicing the eigenVectors to the desired number of clusters--\n",
    "    evec_new = evec[:, :k]\n",
    "\n",
    "    #-------------normalizing the eigenVectors--------------\n",
    "    system = evec.real / np.sqrt(np.linalg.norm(evec.real))\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    system_labels = kmeans.fit_predict(system)\n",
    "\n",
    "\n",
    "    return system, system_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc29afd",
   "metadata": {},
   "source": [
    "## GMM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ac20cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class GMM:\n",
    "    def __init__(self, k, max_iter=5):\n",
    "        self.k = k\n",
    "        self.max_iter = int(max_iter)\n",
    "\n",
    "    def initialize(self, X):\n",
    "        self.shape = X.shape\n",
    "        self.n, self.m = self.shape\n",
    "\n",
    "        self.phi = np.full(shape=self.k, fill_value=1/self.k)\n",
    "        self.weights = np.full( shape=self.shape, fill_value=1/self.k)\n",
    "        \n",
    "        random_row = np.random.randint(low=0, high=self.n, size=self.k)\n",
    "        self.mu = [  X[row_index,:] for row_index in random_row ]\n",
    "        self.sigma = [ np.cov(X.T) for _ in range(self.k) ]\n",
    "\n",
    "    def e_step(self, X):\n",
    "        # E-Step: update weights and phi holding mu and sigma constant\n",
    "        self.weights = self.predict_proba(X)\n",
    "        self.phi = self.weights.mean(axis=0)\n",
    "    \n",
    "    def m_step(self, X):\n",
    "        # M-Step: update mu and sigma holding phi and weights constant\n",
    "        for i in range(self.k):\n",
    "            weight = self.weights[:, [i]]\n",
    "            total_weight = weight.sum()\n",
    "            self.mu[i] = (X * weight).sum(axis=0) / total_weight\n",
    "            self.sigma[i] = np.cov(X.T, \n",
    "                aweights=(weight/total_weight).flatten(), \n",
    "                bias=True)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.initialize(X)\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            self.e_step(X)\n",
    "            self.m_step(X)\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "        likelihood = np.zeros( (self.n, self.k) )\n",
    "        for i in range(self.k):\n",
    "            distribution = multivariate_normal(\n",
    "                mean=self.mu[i], \n",
    "                cov=self.sigma[i],\n",
    "                allow_singular=True\n",
    "            )\n",
    "            likelihood[:,i] = distribution.pdf(X)\n",
    "        \n",
    "        numerator = likelihood * self.phi\n",
    "        denominator = numerator.sum(axis=1)[:, np.newaxis]\n",
    "        weights = numerator / denominator\n",
    "        return weights\n",
    "    \n",
    "    def predict(self, X):\n",
    "        weights = self.predict_proba(X)\n",
    "        return np.argmax(weights, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "145e436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# class GMM:\n",
    "#     def __init__(self, n_components=1, max_iter=100, tol=1e-4):\n",
    "#         self.n_components = n_components\n",
    "#         self.max_iter = max_iter\n",
    "#         self.tol = tol\n",
    "#         self.gmm = None\n",
    "\n",
    "#     def fit(self, X):\n",
    "#         self.gmm = GaussianMixture(n_components=self.n_components, max_iter=self.max_iter, tol=self.tol)\n",
    "#         self.gmm.fit(X)\n",
    "\n",
    "#     def predict_proba(self, X):\n",
    "#         return self.gmm.predict_proba(X)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         return self.gmm.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45d2c1",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409bd0c",
   "metadata": {},
   "source": [
    "## K-Means Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "af891c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = kMeans_implemented(7,np.array(data_k_means))\n",
    "labels2 = kMeans_implemented(15,np.array(data_k_means))\n",
    "labels3 = kMeans_implemented(23,np.array(data_k_means))\n",
    "labels4 = kMeans_implemented(31,np.array(data_k_means))\n",
    "labels5 = kMeans_implemented(45,np.array(data_k_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6762ea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.35235793694748563\n",
      "----------------Purity---------------------------\n",
      "Per cluster purity: [0.63, 0.93, 0.99, 1.0, 0.98, 0.72, 0.83]\n",
      "Purity: 0.9272251452749578\n",
      "--------------Recalls---------------------------\n",
      "Per cluster Recall: [0.189, 0.0892, 0.3665, 0.8109, 0.362, 0.0454, 0.0839]\n",
      "--------------F-measure---------------------------\n",
      "F: 0.37865756371357984\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.5314934128281565\n"
     ]
    }
   ],
   "source": [
    "#labels = kMeans_implemented(7,np.array(data_k_means))\n",
    "contingency_matrix = get_contingency(labels1,np.array(labels_kmeans))\n",
    "evaluation(np.array(data_k_means),contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5271b324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.19353415547078842\n",
      "----------------Purity---------------------------\n",
      "Per cluster purity: [0.97, 0.95, 0.97, 0.98, 0.7, 0.99, 0.98, 0.98, 0.91, 0.97, 1.0, 0.53, 1.0, 0.57, 1.0]\n",
      "Purity: 0.9672770733449645\n",
      "--------------Recalls---------------------------\n",
      "Per cluster Recall: [0.0583, 0.0446, 0.0531, 0.0524, 0.7551, 0.0723, 0.2908, 0.294, 0.189, 0.1071, 0.3826, 0.0045, 0.9913, 0.0203, 0.4283]\n",
      "--------------F-measure---------------------------\n",
      "F: 0.324018694422339\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.353996950256206\n"
     ]
    }
   ],
   "source": [
    "#labels = kMeans_implemented(15,np.array(data_k_means))\n",
    "contingency_matrix = get_contingency(labels2,np.array(labels_kmeans))\n",
    "evaluation(np.array(data_k_means),contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "609a13cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.2619780402966085\n",
      "----------------Purity---------------------------\n",
      "Per cluster purity: [0.98, 1.0, 1.0, 0.67, 0.93, 0.96, 1.0, 0.98, 0.94, 0.97, 1.0, 1.0, 0.67, 1.0, 1.0, 0.54, 0.95, 0.74, 0.98, 0.7, 0.98, 0.69, 1.0]\n",
      "Purity: 0.9368002417814901\n",
      "--------------Recalls---------------------------\n",
      "Per cluster Recall: [0.252, 0.0557, 0.2481, 0.189, 0.7859, 0.0411, 0.1737, 0.1007, 0.0203, 0.1515, 0.0676, 0.1846, 0.8356, 0.1782, 0.0567, 0.0042, 0.0052, 0.0348, 0.0222, 0.7582, 0.0259, 0.0252, 0.106]\n",
      "--------------F-measure---------------------------\n",
      "F: 0.245611790960462\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.26674955009410245\n"
     ]
    }
   ],
   "source": [
    "#labels = kMeans_implemented(23,np.array(data_k_means))\n",
    "contingency_matrix = get_contingency(labels3,np.array(labels_kmeans))\n",
    "evaluation(data_k_means,contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "06166a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.14174278422676723\n",
      "----------------Purity---------------------------\n",
      "Per cluster purity: [1.0, 1.0, 1.0, 0.95, 0.99, 0.65, 1.0, 1.0, 1.0, 0.98, 1.0, 0.98, 1.0, 0.9, 0.95, 0.99, 0.96, 0.87, 0.95, 1.0, 1.0, 0.99, 1.0, 1.0, 0.97, 0.95, 1.0, 0.69, 0.54, 0.93, 0.71]\n",
      "Purity: 0.9756638687785916\n",
      "--------------Recalls---------------------------\n",
      "Per cluster Recall: [0.0024, 0.1489, 0.1019, 0.0565, 0.0789, 0.75, 0.0295, 0.0458, 0.9913, 0.005, 0.1252, 0.2148, 0.1567, 0.0042, 0.0174, 0.0289, 0.037, 0.0137, 0.624, 0.0777, 0.0585, 0.0528, 0.0001, 0.1569, 0.189, 0.7826, 0.3062, 0.8356, 0.0042, 0.0624, 0.0253]\n",
      "--------------F-measure---------------------------\n",
      "F: 0.24337134966674756\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.2778838624593024\n"
     ]
    }
   ],
   "source": [
    "#labels = kMeans_implemented(31,np.array(data_k_means))\n",
    "contingency_matrix = get_contingency(labels4,np.array(labels_kmeans))\n",
    "evaluation(np.array(data_k_means),contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "63ed3f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.1250806575035399\n",
      "----------------Purity---------------------------\n",
      "Per cluster purity: [0.96, 0.68, 1.0, 0.95, 1.0, 0.79, 1.0, 0.99, 0.95, 0.9, 1.0, 0.99, 1.0, 0.85, 0.87, 0.98, 0.96, 1.0, 1.0, 1.0, 0.74, 0.54, 0.96, 1.0, 0.47, 1.0, 1.0, 0.98, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 0.92, 1.0, 0.72, 1.0, 1.0, 0.69, 1.0, 0.97, 1.0]\n",
      "Purity: 0.9765155990273789\n",
      "--------------Recalls---------------------------\n",
      "Per cluster Recall: [0.0368, 0.0041, 0.0288, 0.624, 0.0533, 0.8326, 0.7362, 0.226, 0.0348, 0.0042, 0.0859, 0.0234, 0.0422, 0.0049, 0.0136, 0.0151, 0.0497, 0.0987, 0.1554, 0.1554, 0.0151, 0.0042, 0.0969, 0.0921, 0.0004, 0.0562, 0.0244, 0.0127, 0.0585, 0.0401, 0.0668, 0.0295, 0.0946, 0.005, 0.0135, 0.0316, 0.0047, 0.125, 0.0213, 0.0271, 0.9913, 0.2885, 0.0307, 0.016, 0.0997]\n",
      "--------------F-measure---------------------------\n",
      "F: 0.1657574004027622\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.21820779470553486\n"
     ]
    }
   ],
   "source": [
    "#labels = kMeans_implemented(45,np.array(data_k_means))\n",
    "contingency_matrix = get_contingency(labels5,np.array(labels_kmeans))\n",
    "evaluation(np.array(data_k_means),contingency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3df0d",
   "metadata": {},
   "source": [
    "## Spectral Clustering Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "33d12a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data to use it in spectral clustering\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_spectral, labels_spectral, test_size=0.995, train_size=0.005,stratify=labels_spectral,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c8fe409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter, OrderedDict\n",
    "# d = Counter(y_train)\n",
    "# OrderedDict(sorted(d.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f6f11673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter, OrderedDict\n",
    "# d = Counter(y_test)\n",
    "# OrderedDict(sorted(d.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9b9ad3cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neptune.\n",
      "normal.\n",
      "teardrop.\n",
      "ipsweep.\n",
      "back.\n",
      "satan.\n",
      "smurf.\n",
      "portsweep.\n",
      "pod.\n",
      "nmap.\n",
      "warezclient.\n"
     ]
    }
   ],
   "source": [
    "# Explore the classes in training dataset after splitting\n",
    "for i in y_train.unique():\n",
    "    print(category_map(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0df13c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix=rbf_kernel(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1e6425e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system,labels_spectral=spectral_clustering(sim_matrix,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3abd7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_y={}\n",
    "y=list(y_train.unique())\n",
    "for i in range (len(y)):\n",
    "    dict_y[y_train.unique()[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ef6152af",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_train=np.array([dict_y[label] for label in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "87d4e96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.554049677136008\n",
      "----------------Purity---------------------------\n",
      "Per cluster purity: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.66, 0.75, 0.56]\n",
      "Purity: 0.8038704875325644\n",
      "--------------Recalls---------------------------\n",
      "Per cluster Recall: [0.6808, 0.2, 0.2, 0.2, 0.2, 0.2, 1.0, 0.0015, 0.0879, 0.0347, 0.8621]\n",
      "--------------F-measure---------------------------\n",
      "F: 0.39819856129691494\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.7145515444733904\n"
     ]
    }
   ],
   "source": [
    "contingency_matrix = get_contingency(labels_spectral,new_y_train)\n",
    "evaluation(X_train,contingency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed715399",
   "metadata": {},
   "source": [
    "## Comparison between K-means and Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3ec9fe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.17327577432161273\n",
      "----------------Purity---------------------------\n",
      "Per cluster purity: [1.0, 0.52, 1.0, 0.72, 1.0, 1.0, 0.99, 0.98, 1.0, 0.9, 0.55]\n",
      "Purity: 0.9518049869743208\n",
      "--------------Recalls---------------------------\n",
      "Per cluster Recall: [0.351, 0.0482, 0.0081, 0.0135, 0.0827, 0.0047, 0.3281, 0.1329, 0.8629, 0.0281, 0.9474]\n",
      "--------------F-measure---------------------------\n",
      "F: 0.29239279534715756\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.47301823595087455\n"
     ]
    }
   ],
   "source": [
    "labels6 = kMeans_implemented(11,np.array(X_train))\n",
    "contingency_matrix = get_contingency(labels6,new_y_train)\n",
    "evaluation(X_train,contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b3784e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 11, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 14, 7: 11, 8: 11, 9: 11, 10: 9}\n"
     ]
    }
   ],
   "source": [
    "new_labels_spectral,mapped_spectral = map_and_change(y_train,labels_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f331514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels_spectral=cluster_to_class_name(new_labels_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7e050133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'normal.',\n",
       " 1: 'teardrop.',\n",
       " 2: 'teardrop.',\n",
       " 3: 'teardrop.',\n",
       " 4: 'teardrop.',\n",
       " 5: 'teardrop.',\n",
       " 6: 'pod.',\n",
       " 7: 'normal.',\n",
       " 8: 'normal.',\n",
       " 9: 'normal.',\n",
       " 10: 'neptune.'}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels_spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2becc5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 11, 1: 11, 2: 11, 3: 11, 4: 11, 5: 11, 6: 11, 7: 11, 8: 9, 9: 11, 10: 5}\n"
     ]
    }
   ],
   "source": [
    "new_labels_kmeans,mapped_kmeans = map_and_change(y_train,labels6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "612c8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels_kmeans=cluster_to_class_name(new_labels_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c32c7f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'normal.',\n",
       " 1: 'normal.',\n",
       " 2: 'normal.',\n",
       " 3: 'normal.',\n",
       " 4: 'normal.',\n",
       " 5: 'normal.',\n",
       " 6: 'normal.',\n",
       " 7: 'normal.',\n",
       " 8: 'neptune.',\n",
       " 9: 'normal.',\n",
       " 10: 'ipsweep.'}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "16bb0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_spectral,abnormal_spectral=classify_normality(mapped_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b45f9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_kmeans,abnormal_kmeans=classify_normality(mapped_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8fe9f86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal samples using spectral clustering= 3511\n",
      "Number of abnormal samples using spectral clustering= 1863\n",
      "Number of normal samples using kmeans clustering= 4296\n",
      "Number of abnormal samples using kmeans clustering= 1078\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of normal samples using spectral clustering= {normal_spectral}\")\n",
    "print(f\"Number of abnormal samples using spectral clustering= {abnormal_spectral}\")\n",
    "print(f\"Number of normal samples using kmeans clustering= {normal_kmeans}\")\n",
    "print(f\"Number of abnormal samples using kmeans clustering= {abnormal_kmeans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1843c3ef",
   "metadata": {},
   "source": [
    "## GMM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f00f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gmm = GMM(23)\n",
    "labels = gmm.fit(np.array(data_k_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "cf4b6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = gmm.predict(np.array(data_k_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "004b4cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.24063773251691306\n",
      "----------------Purity---------------------------\n",
      "Per cluster purity: [1.0, 1.0, 0.78, 0.99, 1.0, 1.0, 0.39, 0.9, 0.98, 1.0, 0.85, 0.91, 0.95, 0.87, 1.0, 0.5, 0.51, 0.93, 0.81, 0.71, 0.49, 0.85, 0.91]\n",
      "Purity: 0.9529625101314686\n",
      "--------------Recalls---------------------------\n",
      "Per cluster Recall: [0.2508, 0.0683, 0.0191, 0.4894, 0.0001, 0.0, 0.6, 0.0503, 0.8862, 0.0024, 0.0437, 0.0364, 1.0, 0.0546, 0.9913, 0.125, 0.0034, 0.0394, 0.0008, 0.75, 0.0241, 0.9811, 0.0005]\n",
      "--------------F-measure---------------------------\n",
      "F: 0.3009557073048685\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.6357616803813554\n"
     ]
    }
   ],
   "source": [
    "contingency_matrix = get_contingency(labels,labels_kmeans)\n",
    "evaluation(np.array(data_k_means),contingency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a443b7d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ac1d73c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_to_class_name(labels_dict):\n",
    "    for key in labels_dict.keys():\n",
    "        value=labels_dict[key]\n",
    "        labels_dict[key]=category_map(value)\n",
    "    return labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "de4c97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_normality(mapped_labels):\n",
    "    normal=0\n",
    "    abnormal=0\n",
    "    for label in mapped_labels:\n",
    "        if label==11:\n",
    "            normal+=1\n",
    "        else:\n",
    "            abnormal+=1\n",
    "    return normal,abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "60d26bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map labels resulting in k-means to true labels in able to do predictions\n",
    "def map_and_change(y_train, labels):\n",
    "    mapping = {}\n",
    "    labels = np.array(list(labels))\n",
    "    for i in np.unique(labels):\n",
    "        binary = [int(x) for x in labels == i]\n",
    "        mapping[i] = np.bincount([value for value, flag in zip(y_train, binary) if flag == 1]).argmax()\n",
    "\n",
    "    # Map the cluster labels to the true class labels\n",
    "    mapped_labels = np.array([mapping[label] for label in labels])\n",
    "\n",
    "    # Print the mapped labels\n",
    "    print(mapping)\n",
    "    return mapping, mapped_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "4d24166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_and_change_test(mapping, labels):\n",
    "    mapped_labels = np.array([mapping[label] for label in labels])\n",
    "    return mapped_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "021a29a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{9: 9, 11: 11, 20: 20}\n"
     ]
    }
   ],
   "source": [
    "new_labels,mapped = map_and_change(y_train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "9fa25635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contingency(labels,true):\n",
    "    labels = list(labels)\n",
    "    true = list(true)\n",
    "    true_len=np.unique(np.array(true)).shape[0]\n",
    "    cluster_len=np.unique(np.array(labels)).shape[0]\n",
    "    num_elements = len(labels)\n",
    "    contingency_matrix = np.zeros((true_len,cluster_len))\n",
    "    for i in range(num_elements):\n",
    "        contingency_matrix[true[i],labels[i]] += 1\n",
    "    return contingency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e07ec46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(data, contingency_matrix):\n",
    "    n_total = data.shape[0]\n",
    "    gt_classes=contingency_matrix.shape[0]\n",
    "    predicted_classes=contingency_matrix.shape[1]\n",
    "#     TP, TN, FP, FN = 0, 0, 0, 0\n",
    "#     # True Positive \n",
    "#     for i in range(gt_classes):\n",
    "#         for j in range(predicted_classes):\n",
    "#             if contingency_matrix[i][j] != 1 and contingency_matrix[i][j] != 0:\n",
    "#                 TP += math.comb(int(contingency_matrix[i][j]),2)\n",
    "#     sum_clusters=np.sum(contingency_matrix,axis=0)\n",
    "#     # True Negative \n",
    "#     for i in range(gt_classes):\n",
    "#         for j in range(predicted_classes):\n",
    "#             if i != j:\n",
    "#                 for k in range(gt_classes):\n",
    "#                     temp = contingency_matrix[k,i]*(sum_clusters[j]) - contingency_matrix[k,j])\n",
    "#                     TN += temp\n",
    "#     TN = TN/2\n",
    "    \n",
    "#     # False Positive \n",
    "#     for i in range(gt_classes):\n",
    "#         s_temp=np.sum(contingency_matrix[i])\n",
    "#         for j in range(predicted_classes):\n",
    "#             temp = contingency_matrix[i][j]*(s_temp-contingency_matrix[i][j])\n",
    "#             FP += temp \n",
    "#         FP=FP/2\n",
    "#     # False Negative \n",
    "#     for i in range(gt_classes):\n",
    "#         for j in range(predicted_classes):\n",
    "#             if i != j:\n",
    "#                 for k in range(predicted_classes):\n",
    "#                     temp = contingency_matrix[k,i]*(contingency_matrix[k,j])\n",
    "#                     FN += temp\n",
    "#     FN /= 2\n",
    "\n",
    "#     # Jaccard Index\n",
    "#     jacc = TP / (TP + FN + FP)\n",
    "\n",
    "#     # Rand Index\n",
    "#     rand = (TP + TN)/ (TP + FN + FP + TN)\n",
    "#     print('---------Confusion Matrix----------------------')\n",
    "#     print(f\"Rand Index: {rand}\")\n",
    "    \n",
    "#     print(f\"Jaccard Index: {jacc}\")\n",
    "#     print(f'TP= {TP},TN= {TN},FN= {FN},FP= {FP}')\n",
    "    \n",
    "    ht_c = 0\n",
    "    for i in range(predicted_classes):\n",
    "        cluster_elem = np.sum(contingency_matrix[:,i])\n",
    "        for j in range(gt_classes):  \n",
    "            temp = contingency_matrix[j][i]/cluster_elem\n",
    "            if temp != 0:\n",
    "                ht_c += temp*math.log(temp,2)*(cluster_elem/n_total)\n",
    "    ht_c = -1*ht_c\n",
    "    print('---------Conditional Entropy--------------------')\n",
    "    print(f\"Conditional Entropy: {ht_c}\")\n",
    "    \n",
    "    print('----------------Purity---------------------------')\n",
    "    purity=0\n",
    "    purities=[]\n",
    "    recalls=[]\n",
    "    for i in range(predicted_classes):\n",
    "        cluster_sum=np.sum(contingency_matrix[:,i])\n",
    "        class_max=np.max(contingency_matrix[:,i])\n",
    "        a=contingency_matrix[:,i]\n",
    "        max_index=a.argmax()\n",
    "        purities.append(round((class_max/cluster_sum),2))\n",
    "        recalls.append(round((class_max/np.sum(contingency_matrix[max_index,:])),4))\n",
    "        purity+=(class_max/cluster_sum) * (cluster_sum/n_total)\n",
    "    #purity = np.sum(np.max(contingency_matrix, axis =0))/np.sum(contingency_matrix)\n",
    "    print(f\"Per cluster purity: {purities}\")\n",
    "    print(f\"Purity: {purity}\")\n",
    "    print('--------------Recalls---------------------------')\n",
    "    print(f\"Per cluster Recall: {recalls}\")\n",
    "    print('--------------F-measure---------------------------')\n",
    "    # a row for each cluster, and columns are precision, recall and F-measure respectively\n",
    "    \n",
    "    f_measure=0\n",
    "    for i in range(predicted_classes):\n",
    "        f_measure+=(2*purities[i]*recalls[i])/(purities[i]+recalls[i])\n",
    "    f_measure=f_measure/predicted_classes\n",
    "    print(f\"F: {f_measure}\")\n",
    "    \n",
    "    print('--------------Max matching------------------------')\n",
    "    row_ind, col_ind = linear_sum_assignment(contingency_matrix, maximize=True)\n",
    "    contingency_reordered = contingency_matrix[row_ind][:, col_ind]\n",
    "    #print(contingency_reordered)\n",
    "    max_match = np.sum(np.diag(contingency_reordered))/np.sum(contingency_matrix)\n",
    "    print(f\"Max Matching: {max_match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4b8fe",
   "metadata": {},
   "source": [
    "# Testing K-means using Test Data set and Mapping Clusters to Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502644a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_spectral, labels_spectral, test_size=0.995, train_size=0.005,stratify=labels_spectral,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a52ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=23, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26774a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b402396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping, train_labels = map_and_change(y_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = kmeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5091199",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = map_and_change_test(mapping,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_labels, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7435e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
