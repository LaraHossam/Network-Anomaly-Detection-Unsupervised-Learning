{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152c8828",
   "metadata": {},
   "source": [
    "# Network Anomaly Detection using Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dcf3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import random\n",
    "random.seed(42)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813b800",
   "metadata": {},
   "source": [
    "# 1. Importing Data and Understanding Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ac7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.data_preprocessing import preprocess_data_10, preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36eab8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_k_means, labels_kmeans = preprocess_data_10()\n",
    "data_spectral, labels_spectral = preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98946dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, 968),\n",
       "             (1, 30),\n",
       "             (2, 8),\n",
       "             (3, 53),\n",
       "             (4, 12),\n",
       "             (5, 3723),\n",
       "             (6, 19),\n",
       "             (7, 9),\n",
       "             (8, 7),\n",
       "             (9, 242149),\n",
       "             (10, 1554),\n",
       "             (11, 812814),\n",
       "             (12, 3),\n",
       "             (13, 4),\n",
       "             (14, 206),\n",
       "             (15, 3564),\n",
       "             (16, 10),\n",
       "             (17, 5019),\n",
       "             (18, 3007),\n",
       "             (19, 2),\n",
       "             (20, 918),\n",
       "             (21, 893),\n",
       "             (22, 20)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "d = Counter(labels_spectral)\n",
    "OrderedDict(sorted(d.items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0051450",
   "metadata": {},
   "source": [
    "# 2.  Clustering Using K-Means and Normalized Cut (Your implementation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b39528",
   "metadata": {},
   "source": [
    "### K-Means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06553527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It takes two attrs k number of centroids and the whole data set number of samples x features\n",
    "\n",
    "def kMeans_implemented(k,data):\n",
    "    centroids=[]\n",
    "    num_points=data.shape[0]\n",
    "    num_features=data.shape[1]\n",
    "    \n",
    "    #Appending random points to be our centroids according to the number of ks\n",
    "    for i in range(k):\n",
    "        centroids.append(data[random.randint(0, num_points)])\n",
    "    clusters={}\n",
    "    t=0\n",
    "    while(True):\n",
    "        labels=[]\n",
    "        #Initialize empty clusters\n",
    "        for i in range (k):\n",
    "            clusters[i]=[]\n",
    "            \n",
    "        #Classify the points according to the closest centroid\n",
    "        for i in range(num_points):\n",
    "            distances=[]\n",
    "            for j in range(k):\n",
    "                distances.append(np.linalg.norm(data[i]-centroids[j]))\n",
    "            clusters[distances.index(min(distances))].append(data[i])\n",
    "            labels.append(distances.index(min(distances)))\n",
    "        new_centroids=np.zeros((k,num_features))\n",
    "        \n",
    "        #Measuring the new centroids\n",
    "        for i in range(k):\n",
    "            new_centroids[i]=np.mean(clusters[i],axis=0)\n",
    "        if(centroids==new_centroids).all():\n",
    "            break\n",
    "        else:\n",
    "            centroids=new_centroids\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225e45c",
   "metadata": {},
   "source": [
    "### Spectral Clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6f2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def spectral_clustering(A,k):\n",
    "        \n",
    "    #--------------computing the degree matrix-------------\n",
    "    d = np.diag(np.sum(A, axis=1))\n",
    "\n",
    "    #--------------------computing L-----------------------\n",
    "    L = d-A\n",
    "\n",
    "    #---------------------computing La---------------------\n",
    "    #computing the inverse of the dgree matrix\n",
    "    inv_degree = np.linalg.inv(d)\n",
    "    La = np.dot(inv_degree, L)\n",
    "\n",
    "    #---computing the eigenValues and eigenVectors of La---\n",
    "    e_val, evec = np.linalg.eig(La)\n",
    "\n",
    "    #----------sorting the eigenValues ascending----------- \n",
    "    idx = np.argsort(eval)\n",
    "    e_val = e_val[idx]\n",
    "\n",
    "    #---sorting the eigenVectors according to their corresponding eigenValues---\n",
    "    evec = evec[:, idx]\n",
    "\n",
    "    #--slicing the eigenVectors to the desired number of clusters--\n",
    "    evec_new = evec[:, :k]\n",
    "\n",
    "    #-------------normalizing the eigenVectors--------------\n",
    "    system = evec.real / np.sqrt(np.linalg.norm(evec.real))\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    system_labels = kmeans.fit_predict(system)\n",
    "\n",
    "\n",
    "    return system, system_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc29afd",
   "metadata": {},
   "source": [
    "## GMM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Create a Gaussian Mixture Model with 23 components\n",
    "gmm = GaussianMixture(n_components=23)\n",
    "\n",
    "# Fit the model to the data\n",
    "gmm.fit(X_train)\n",
    "\n",
    "# Predict the cluster labels for the data\n",
    "labels = gmm.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21220309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping, labels = map_and_change(y_train,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45d2c1",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409bd0c",
   "metadata": {},
   "source": [
    "## K-Means Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af891c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = kMeans_implemented(7,np.array(data_k_means))\n",
    "labels2 = kMeans_implemented(15,np.array(data_k_means))\n",
    "labels3 = kMeans_implemented(23,np.array(data_k_means))\n",
    "labels4 = kMeans_implemented(31,np.array(data_k_means))\n",
    "labels5 = kMeans_implemented(45,np.array(data_k_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6762ea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.3560348999697181\n",
      "----------------Purity---------------------------\n",
      "Purity: 0.9272320140672868\n",
      "--------------F-measure---------------------------\n",
      "F: 0.37852397344067573\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.5359237838803181\n"
     ]
    }
   ],
   "source": [
    "#labels = kMeans_implemented(7,np.array(data_k_means))\n",
    "contingency_matrix = get_contingency(7,labels1,np.array(labels_kmeans))\n",
    "evaluation(np.array(data_k_means),contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5271b324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.18373219846534355\n",
      "----------------Purity---------------------------\n",
      "Purity: 0.9736444438338849\n",
      "--------------F-measure---------------------------\n",
      "F: 0.41680386111088813\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.42480733037517343\n"
     ]
    }
   ],
   "source": [
    "#labels = kMeans_implemented(15,np.array(data_k_means))\n",
    "contingency_matrix = get_contingency(15,labels2,np.array(labels_kmeans))\n",
    "evaluation(np.array(data_k_means),contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "609a13cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Confusion Matrix----------------------\n",
      "Rand Index: 0.6102798232289484\n",
      "Jaccard Index: 0.21108268697057267\n",
      "TP= 1105045771,TN= 5362436707.0,FN= 4097006802.0,FP= 33079625.0\n",
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.15197479620500717\n",
      "----------------Purity---------------------------\n",
      "Purity: 0.9755677056859864\n",
      "--------------F-measure---------------------------\n",
      "F: 0.2899171883013299\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.33036830464467737\n"
     ]
    }
   ],
   "source": [
    "#labels = kMeans_implemented(23,np.array(data_k_means))\n",
    "contingency_matrix = get_contingency(23,labels3,np.array(labels_kmeans))\n",
    "evaluation(data_k_means,contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06166a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.1373032330683246\n",
      "----------------Purity---------------------------\n",
      "Purity: 0.9748739576607641\n",
      "--------------F-measure---------------------------\n",
      "F: 0.2474324622398687\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.29583888560713256\n"
     ]
    }
   ],
   "source": [
    "#labels = kMeans_implemented(31,np.array(data_k_means))\n",
    "contingency_matrix = get_contingency(31,labels4,np.array(labels_kmeans))\n",
    "evaluation(np.array(data_k_means),contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63ed3f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Conditional Entropy--------------------\n",
      "Conditional Entropy: 0.14802197270368977\n",
      "----------------Purity---------------------------\n",
      "Purity: 0.9694476117209071\n",
      "--------------F-measure---------------------------\n",
      "F: 0.16965070847395466\n",
      "--------------Max matching------------------------\n",
      "Max Matching: 0.21982882969516299\n"
     ]
    }
   ],
   "source": [
    "#labels = kMeans_implemented(45,np.array(data_k_means))\n",
    "contingency_matrix = get_contingency(45,labels5,np.array(labels_kmeans))\n",
    "evaluation(np.array(data_k_means),contingency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3df0d",
   "metadata": {},
   "source": [
    "## Spectral Clustering Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33d12a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data to use it in spectral clustering\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_spectral, labels_spectral, test_size=0.995, train_size=0.005,stratify=labels_spectral,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8fe409b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, 5),\n",
       "             (5, 19),\n",
       "             (9, 1211),\n",
       "             (10, 8),\n",
       "             (11, 4063),\n",
       "             (14, 1),\n",
       "             (15, 18),\n",
       "             (17, 25),\n",
       "             (18, 15),\n",
       "             (20, 5),\n",
       "             (21, 4)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "d = Counter(y_train)\n",
    "OrderedDict(sorted(d.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6f11673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, 963),\n",
       "             (1, 30),\n",
       "             (2, 8),\n",
       "             (3, 53),\n",
       "             (4, 12),\n",
       "             (5, 3704),\n",
       "             (6, 19),\n",
       "             (7, 9),\n",
       "             (8, 7),\n",
       "             (9, 240938),\n",
       "             (10, 1546),\n",
       "             (11, 808751),\n",
       "             (12, 3),\n",
       "             (13, 4),\n",
       "             (14, 205),\n",
       "             (15, 3546),\n",
       "             (16, 10),\n",
       "             (17, 4994),\n",
       "             (18, 2992),\n",
       "             (19, 2),\n",
       "             (20, 913),\n",
       "             (21, 889),\n",
       "             (22, 20)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "d = Counter(y_test)\n",
    "OrderedDict(sorted(d.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df13c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix=rbf_kernel(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6425e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system,labels=spectral_clustering(sim_matrix,23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_matrix = get_contingency(23,labels,y_train)\n",
    "evaluation(X_train,contingency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed715399",
   "metadata": {},
   "source": [
    "## Comparison between K-means and Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kMeans_implemented(23,np.array(X_train))\n",
    "contingency_matrix = get_contingency(23,labels,np.array(y_train))\n",
    "evaluation(X_train,contingency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1843c3ef",
   "metadata": {},
   "source": [
    "## GMM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f00f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = gmm(23,np.array(X_train))\n",
    "contingency_matrix = get_contingency(23,labels,np.array(y_train))\n",
    "evaluation(X_train,contingency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a443b7d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60d26bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map labels resulting in k-means to true labels in able to do predictions\n",
    "def map_and_change(y_train, labels):\n",
    "    mapping = {}\n",
    "    labels = np.array(list(labels))\n",
    "    for i in np.unique(labels):\n",
    "        binary = [int(x) for x in labels == i]\n",
    "        mapping[i] = np.bincount([value for value, flag in zip(y_train, binary) if flag == 1]).argmax()\n",
    "\n",
    "    # Map the cluster labels to the true class labels\n",
    "    mapped_labels = np.array([mapping[label] for label in labels])\n",
    "\n",
    "    # Print the mapped labels\n",
    "    print(mapping)\n",
    "    return mapping, mapped_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d24166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_and_change_test(mapping, labels):\n",
    "    mapped_labels = np.array([mapping[label] for label in labels])\n",
    "    return mapped_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "021a29a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m map_and_change(\u001b[43my_train\u001b[49m,labels)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "new_labels = map_and_change(y_train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fa25635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contingency(k,labels,true):\n",
    "    labels = list(labels)\n",
    "    true = list(true)\n",
    "    num_classes = k\n",
    "    num_elements = len(labels)\n",
    "    contingency_matrix = np.zeros((23,k))\n",
    "    for i in range(num_elements):\n",
    "        contingency_matrix[true[i],labels[i]] += 1\n",
    "    return contingency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e07ec46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(data, contingency_matrix):\n",
    "    n_total = data.shape[0]\n",
    "    gt_classes=contingency_matrix.shape[0]\n",
    "    predicted_classes=contingency_matrix.shape[1]\n",
    "#     TP, TN, FP, FN = 0, 0, 0, 0\n",
    "#     # True Positive \n",
    "#     for i in range(gt_classes):\n",
    "#         for j in range(predicted_classes):\n",
    "#             if contingency_matrix[i][j] != 1 and contingency_matrix[i][j] != 0:\n",
    "#                 TP += math.comb(int(contingency_matrix[i][j]),2)\n",
    "\n",
    "#     # True Negative \n",
    "#     for i in range(gt_classes):\n",
    "#         for j in range(predicted_classes):\n",
    "#             if i != j:\n",
    "#                 for k in range(predicted_classes):\n",
    "#                     temp = contingency_matrix[k,i]*(np.sum(contingency_matrix[:,j]) - contingency_matrix[k,j])\n",
    "#                     TN += temp\n",
    "#     TN = TN/2\n",
    "\n",
    "#     # False Positive \n",
    "#     for i in range(gt_classes):\n",
    "#         for j in range(predicted_classes):\n",
    "#             temp = contingency_matrix[j,i]*(np.sum(contingency_matrix[:,i])-contingency_matrix[j,i])/2\n",
    "#             FP += temp\n",
    "\n",
    "#     # False Negative \n",
    "#     for i in range(gt_classes):\n",
    "#         for j in range(predicted_classes):\n",
    "#             if i != j:\n",
    "#                 for k in range(predicted_classes):\n",
    "#                     temp = contingency_matrix[k,i]*(contingency_matrix[k,j])\n",
    "#                     FN += temp\n",
    "#     FN /= 2\n",
    "\n",
    "#     # Jaccard Index\n",
    "#     jacc = TP / (TP + FN + FP)\n",
    "\n",
    "#     # Rand Index\n",
    "#     rand = (TP + TN)/ (TP + FN + FP + TN)\n",
    "#     print('---------Confusion Matrix----------------------')\n",
    "#     print(f\"Rand Index: {rand}\")\n",
    "    \n",
    "#     print(f\"Jaccard Index: {jacc}\")\n",
    "#     print(f'TP= {TP},TN= {TN},FN= {FN},FP= {FP}')\n",
    "    \n",
    "    ht_c = 0\n",
    "    for i in range(predicted_classes):\n",
    "        cluster_elem = np.sum(contingency_matrix[:,i])\n",
    "        for j in range(gt_classes):  \n",
    "            temp = contingency_matrix[j][i]/cluster_elem\n",
    "            if temp != 0:\n",
    "                ht_c += temp*math.log(temp,2)*(cluster_elem/n_total)\n",
    "    ht_c = -1*ht_c\n",
    "    print('---------Conditional Entropy--------------------')\n",
    "    print(f\"Conditional Entropy: {ht_c}\")\n",
    "    \n",
    "    print('----------------Purity---------------------------')\n",
    "    purity=0\n",
    "    purities=[]\n",
    "    recalls=[]\n",
    "    for i in range(predicted_classes):\n",
    "        cluster_sum=np.sum(contingency_matrix[:,i])\n",
    "        class_max=np.max(contingency_matrix[:,i])\n",
    "        a=contingency_matrix[:,i]\n",
    "        max_index=a.argmax()\n",
    "        purities.append(class_max/cluster_sum)\n",
    "        recalls.append(class_max/np.sum(contingency_matrix[max_index,:]))\n",
    "        purity+=(class_max/cluster_sum) * (cluster_sum/n_total)\n",
    "    #purity = np.sum(np.max(contingency_matrix, axis =0))/np.sum(contingency_matrix)\n",
    "    print(f\"Purity: {purity}\")\n",
    "    \n",
    "    print('--------------F-measure---------------------------')\n",
    "    # a row for each cluster, and columns are precision, recall and F-measure respectively\n",
    "    \n",
    "    f_measure=0\n",
    "    for i in range(predicted_classes):\n",
    "        f_measure+=(2*purities[i]*recalls[i])/(purities[i]+recalls[i])\n",
    "    f_measure=f_measure/predicted_classes\n",
    "    print(f\"F: {f_measure}\")\n",
    "    \n",
    "    print('--------------Max matching------------------------')\n",
    "    row_ind, col_ind = linear_sum_assignment(contingency_matrix, maximize=True)\n",
    "    contingency_reordered = contingency_matrix[row_ind][:, col_ind]\n",
    "    #print(contingency_reordered)\n",
    "    max_match = np.sum(np.diag(contingency_reordered))/np.sum(contingency_matrix)\n",
    "    print(f\"Max Matching: {max_match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4b8fe",
   "metadata": {},
   "source": [
    "# Testing K-means using Test Data set and Mapping Clusters to Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502644a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_spectral, labels_spectral, test_size=0.995, train_size=0.005,stratify=labels_spectral,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a52ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=23, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26774a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b402396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping, train_labels = map_and_change(y_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = kmeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5091199",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = map_and_change_test(mapping,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_labels, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7435e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
